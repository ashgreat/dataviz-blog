[
  {
    "path": "posts/welcome/",
    "title": "Welcome to R Data Visualization",
    "description": "Welcome to my new blog, R Data Visualization. I hope youe enjoy the code\nand visualizations!",
    "author": [
      {
        "name": "Ashwin Malshe",
        "url": "www.ashwinmalshe.com"
      }
    ],
    "date": "2020-10-31",
    "categories": [],
    "contents": "\nMy main website is ashwinmalshe.com. However, due to some configurations issues, I am unable to update it. It has made it difficult for me to post new blog posts. Therefore, while I am porting my website to another project, I decided to start this blog. Here I am gradually making available all the old posts from my website. In addition, I will add new material.\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-31T23:07:24-05:00",
    "input_file": "welcome.utf8.md"
  },
  {
    "path": "posts/2020-10-31-msda-faculty/",
    "title": "MSDA Faculty",
    "description": "A list of MSDA full-time faculty",
    "author": [
      {
        "name": "Ashwin Malshe",
        "url": "www.ashwinmalshe.com"
      }
    ],
    "date": "2020-10-31",
    "categories": [],
    "contents": "\nWe don’t have an official listing for the faculty teaching in the MS in Data Analytics (MSDA) program at UTSA as we don’t have any professors permanently assigned to the program. However, there are a few professors, including me, who have been teaching regularly in MSDA. The following table lists these professors and the links to their profiles.\n\n\nCourse\n\n\nFaculty\n\n\nDA6213. Data-Driven Decision Making and Design\n\n\nYeonjoo Park\n\n\nDA6223. Data Analytics Tools and Techniques\n\n\nWenbo Wu\n\n\nDA6233. Data Analytics Visualization and Communication\n\n\nAshwin Malshe\n\n\nDA6813. Data Analytics Applications\n\n\nArka Roy\n\n\nAshwin Malshe\n\n\nDA6823. Data Analytics Practicum I\n\n\nMax Kilger\n\n\nDA6833. Data Analytics Practicum II\n\n\nMax Kilger\n\n\nIS6713. Data Foundations\n\n\nAnthony Rios\n\n\nIS6733. Deep Learning on Cloud Platforms\n\n\nPaul Rad\n\n\nSTA6443. Statistical Modeling\n\n\nYeonjoo Park\n\n\nSTA 6543. Predictive Modeling\n\n\nMin Wang\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-31T20:14:54-05:00",
    "input_file": "msda-faculty.utf8.md"
  },
  {
    "path": "posts/2020-10-31-plotting-election-win-probabilities/",
    "title": "Mapping Election Win Probabilities",
    "description": "I show how to create a election map using ggplot2",
    "author": [
      {
        "name": "Ashwin Malshe",
        "url": "www.ashwinmalshe.com"
      }
    ],
    "date": "2020-10-31",
    "categories": [],
    "contents": "\nIn this post, I will show you how to make a map using ggplot2. For this, I am going to use an excellent post by Andrew Gelman.\nFivethirtyeight daily updates the probabilities of Trump and Biden wins based on multiple polls and their own model.1 They also make available their simulation outcomes as a json file. Next, I merged the cleaned simulation data with US map data. I will create a separate post to show you how to read, clean, and merge these data sets.\nRead the data sets and load packages\nI have saved all the required data sets as a .rda file on Github. You can directly read them into your R code without saving it first.\n\n\nload(url(\"https://github.com/ashgreat/DA6233/blob/master/sim-elect.rda?raw=true\"))\n\n\n\nI will use ggrepel package to make sure that the state labels don’t overlap. If you don’t have this package installed, run install.packages(\"ggrepel\") in the RStudio console.\n\n\nlibrary(tidyverse)\nlibrary(ggrepel)\n\n\n\nMaking the map\nNow we are ready to make the map. We will use trump_wins data set. This data set has results of 40,000 simulations. Each simulation shows whether Trump will win or lose a state. There are results for 50 states and Washington D.C. There are five more results for, what I think is, regional data. We will not use those results.\nTrump probability of winning each state is simply the column means of this data set. In the following code the first four lines calculate the probabilities and restructure the data so that it is easier to merge with the data on maps.\n\n\ndt <- trump_wins %>% \n  summarize(across(everything(), mean)) %>%\n  mutate(across(everything(), ~ round(.x * 100, 2))) %>% \n  pivot_longer(cols = everything(), names_to = \"state_abb\", values_to = \"prob\") %>% \n  inner_join(select(state_names, -lat, -long), by = \"state_abb\") %>% \n  inner_join(fifty_states, by = c(\"state_low\" = \"id\"))\n\n\n\nFinally, we create a map using dt. The labels of the states are split into two groups. Many northeastern states show up small on the map so their names are no readable easily. Therefore, we need to show them a little bit away from the map. For this we will use geom_text_repel() function from ggrepel package.\n\n\ndt %>%\n  ggplot(aes(x = long, y = lat)) +\n  geom_polygon(aes(group = group, fill = prob), color = \"#d8dee9\", size = 0.05) +\n  geom_text(data = filter(state_label, \n                          !state_abb %in% c(\"MA\", \"RI\", \"CT\", \"NJ\", \"DE\", \"DC\", \"MD\")), \n            aes(label = state_abb), \n            size = 3, hjust = 0.5, family = \"Roboto Condensed\") +\n  geom_text_repel(data = filter(state_label, \n                                state_abb %in% c(\"MA\", \"RI\", \"CT\", \"NJ\", \"DE\", \"DC\", \"MD\")),\n                  aes(label = state_abb), \n                  nudge_x = 5, \n                  segment.size  = 0.2, \n                  segment.color = \"grey50\",\n                  direction     = \"y\", \n                  size = 3, \n                  hjust = 0.5, \n                  family = \"Roboto Condensed\") +\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45) +\n  scale_fill_gradient2(low = \"#0063c4\", \n                       mid = \"#d8dee9\", \n                       high = \"#ef2e69\",\n                       midpoint = 50,\n                       labels = c(\"0%\", \"25%\", \"50%\", \"75%\", \"100%\"),\n                       guide = guide_colourbar(barwidth = 30, \n                                              barheight = 0.4,\n                                              title.position = \"top\")) + \n  labs(fill = \"Probability of Trump Winning the State\") +\n  ggthemes::theme_map() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(family = \"Roboto Condensed\")) \n\n\n\n\n\nYou can check out the maps and other information on their website: https://projects.fivethirtyeight.com/trump-biden-election-map/↩︎\n",
    "preview": "posts/2020-10-31-plotting-election-win-probabilities/plotting-election-win-probabilities_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-10-31T23:02:19-05:00",
    "input_file": "plotting-election-win-probabilities.utf8.md"
  },
  {
    "path": "posts/2020-10-31-plotting-covid-19-pandemic/",
    "title": "Plotting Covid-19 Pandemic",
    "description": "Interactive plot of Covid-19 cases",
    "author": [
      {
        "name": "Ashwin Malshe",
        "url": "www.ashwinmalshe.com"
      }
    ],
    "date": "2020-03-08",
    "categories": [],
    "contents": "\nIn this post, we will visualize spread of worldwide COVID-19 cases through time. I obtained the data from Rami Krispin’s website: https://ramikrispin.github.io/coronavirus/ using coronovirus package. I also decided to do some experimentation using John Coene’s fantastic echarts4r package, which allows us to access echarts API.\nLoad the libraries and get the data in the R session.\n\n\nlibrary(dplyr)\nlibrary(echarts4r)\nlibrary(coronavirus)\n\n# Get the data\ndata(\"coronavirus\")\n\n\n\nData Preparation\nPrint out the first 6 observations.\n\n\nhead(coronavirus)\n\n\n        date province     country      lat     long      type cases\n1 2020-01-22          Afghanistan 33.93911 67.70995 confirmed     0\n2 2020-01-23          Afghanistan 33.93911 67.70995 confirmed     0\n3 2020-01-24          Afghanistan 33.93911 67.70995 confirmed     0\n4 2020-01-25          Afghanistan 33.93911 67.70995 confirmed     0\n5 2020-01-26          Afghanistan 33.93911 67.70995 confirmed     0\n6 2020-01-27          Afghanistan 33.93911 67.70995 confirmed     0\n\nWe are interested in date and type. Let’s take a look at the distinct values for type.\n\n\ncoronavirus %>% count(type)\n\n\n       type     n\n1 confirmed 75576\n2     death 75576\n3 recovered 71910\n\nThere are only 3 values: confirmed, death, and recovered. Next we will create sum of cases for each of the values and store them in separate data sets.\n\n\ndt1 <- coronavirus %>% \n  filter(type == \"confirmed\") %>% \n  group_by(date) %>% \n  summarize(Confirmed = sum(cases, na.rm = TRUE), .groups = \"drop\")\n\ndt2 <- coronavirus %>% \n  filter(type == \"death\") %>% \n  group_by(date) %>% \n  summarize(Death = sum(cases, na.rm = TRUE), .groups = \"drop\")\n\n\ndt3 <- coronavirus %>% \n  filter(type == \"recovered\") %>% \n  group_by(date) %>% \n  summarize(Recovered = sum(cases, na.rm = TRUE), .groups = \"drop\")\n\n\n\nFinally, we will merge the 3 datasets so that we will have the counts of each type in separate columns.\n\n\ndt <- dt1 %>% \n  inner_join(dt2, by = \"date\") %>% \n  inner_join(dt3, by = \"date\")\n\n\n\nPlot\nFinally, time to make the plot! Note how we can build this plot in separate elements.\n\n\ndt %>% \n  e_charts(x = date) %>% \n  e_line(serie = Confirmed) %>% \n  e_line(serie = Death) %>% \n  e_line(serie = Recovered) %>% \n  e_tooltip(trigger = \"axis\") %>% \n  e_datazoom(type = \"slider\") %>% \n  e_title(\"Worldwide COVID-19 cases\") %>% \n  e_theme(\"bee-insipired\") \n\n\npreserve71574d1b44708db8\n\n\nThis plot is interactive so you can hover over the plot to get the exact readings. You can also toggle time series on or off by clicking on the legends on top.\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-31T23:04:43-05:00",
    "input_file": "plotting-covid-19-pandemic.utf8.md"
  }
]
